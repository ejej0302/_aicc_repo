{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 정리 (업데이트예정)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **모델 실험 요약** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|사용 모델|best_loss's acc|best_acc within epoch 10|\n",
    "|------|---|---|\n",
    "|google_bert|0.7804|0.7855|\n",
    "|skt kobert|0.7772|0.7918|\n",
    "|kcbert+nomecab|0.7945|0.8006|\n",
    "|kcbert+mecab|0.7994|0.8024|\n",
    "|kcbert+(augment_data)+nomecab|0.8019|0.8060|\n",
    "|kcbert+(augment_data)+mecab|0.8110|0.8110|\n",
    "|kcbert+(augment_data)+mecab+LM pretraing|0.8176|<span style=\"color:red\">0.8239</span>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "> **발표 시나리오 정리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- po부서의 backlog 정리 , 수행여부\n",
    "- 과제 목표 달성을 위해 역량 강화 방법, 결과 (발표자료 전체적으로 스토리있게 구성) \n",
    "- 성장한 점 : 3개월동안 자연어처리 딥러닝 학습을 통해 성장한 부분 (3개월 AI개발자 교육과정, NLP 외부강사 강의, 논문리뷰 및 파이토치 코딩 커스텀화, api개발 웹공부)\n",
    "- 힘들었던 점 : (수행중 어려웠던 점, 어떻게 해결했는가?)\n",
    "            1) top1 accuracy가 생각보다 80%를 넘기지 못해 고생을 했던 점 \n",
    "             - 추가 데이터 확보로 accuracy 를 80% 이상으로 향상  \n",
    "            2) 공개된 pretrained 버트가 범용적으로 사용하기는 좋지만, 특수 도메인에 적용하기에는 한계가 존재했고 이것을 극복하기 위해 다양한 방법을 시도\n",
    "             - pretraining LM 시도 및 accuracy 향상(82.3%)\n",
    "- 과제의 기여 : 1) 고객 - 2선 상담 분류를 위한 상담사의 휴먼에러 및 재처리를 방지할수있어서 시간적, 업무적으로 효율성 향상 기대 \n",
    "            2) 실무적용방안 - AICC 보이스봇 상담내역(대화록)을 분류하여 O&M서비스에서 대화에 대한 분류 인사이트 제공 가능 \n",
    "            - 방법은 데이터만 보이스봇 데이터로 교체하여 과제에서 개발한 pre-training 및 fine-tuning 모델을 적용하여 분류 정확도 향상에 기여할 것으로 예상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    ">**po부서의 백로그**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- bert 코드에 맞게 pytorch/ tf2.0 중 하나 선택하여 환경 설정 - **완료**\n",
    "- GPU 서버에 pytorch/tf 라이브러리 버전에 맞게 cuda & cudnn 설정 - **완료** \n",
    "- 한국어 텍스트 전처리 방법 학습 - **완료** : 정규표현식 적용\n",
    "- ISC 데이터에서 전처리가 필요한 부분들 파악하여 전처리 모듈 개발 - **완료** (api)  \n",
    "- text 정제 및 normalization(형태소 분석기 태우기, 여러 형태소 분석기 중 어떤 형태소 분석기 사용할지 선택) - **완료** : mecab 적용\n",
    "- bert 기반 텍스트 분류 엔진 공부 - **완료**: 김기현 nlp 학습, 논문리뷰 및 깃허브 커스터마이징\n",
    "- huggingface BERT오픈소스 코드 구조 파악 - **완료**: 소스코드 연구 완료\n",
    "- 모델 학습 및 하이퍼파라미터 튜닝 - **완료**: 다양한 실험 진행\n",
    "- google bert 사용 시 top1-accuracy > 80%  - **부분 달성** : 구글버트로 best acc 기준 78.5%까지는 달성\n",
    "- skt , etri bert 사용 시 top1-acc > 83%  - **부분 달성** : kcbert + pretraining LM 으로 82.3% 까지 달성\n",
    "- 위 모델들을 argument로 갈아끼울 수 있도록 adaptor 제작 - **완료** (api)\n",
    "- 분류 api 개발 - **완료** (api)\n",
    "- api 성능 테스트 (cpu, gpu 환경에서 tps) - **완료**  (api)\n",
    "- 시연용 프로토타입 고민 - **완료** : 데모웹페이지 구현 (api ; http://211.253.8.112:5000/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작성자 : 박은진"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
